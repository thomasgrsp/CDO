{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "src_breast_cancer = 'breast_cancer/wdbc.csv'\n",
    "src_ionosphere = 'ionosphere/ionosphere.csv'\n",
    "\n",
    "bc_data = pd.read_csv(src_breast_cancer, delimiter=',')\n",
    "io_data = pd.read_csv(src_ionosphere, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568,) (568, 30)\n",
      "(350,) (350, 34)\n"
     ]
    }
   ],
   "source": [
    "# Get data as np array and split bc_classes/bc_features\n",
    "bc_classes = bc_data[bc_data.columns[1]].values\n",
    "bc_features = bc_data[bc_data.columns[2:]].values\n",
    "print(bc_classes.shape, bc_features.shape)\n",
    "io_classes = io_data[io_data.columns[-1]].values\n",
    "io_features = io_data[io_data.columns[:-1]].values\n",
    "print(io_classes.shape, io_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of maligne:  211\n",
      "Number of benigne:  0\n",
      "Number of bad:  126\n",
      "Number of good:  0\n"
     ]
    }
   ],
   "source": [
    "# Process bc_features into 0 and 1 class\n",
    "bc_classes[bc_classes == 'M'] = 1\n",
    "bc_classes[bc_classes == 'B'] = -1\n",
    "print('Number of maligne: ', np.count_nonzero(bc_classes == 1))\n",
    "print('Number of benigne: ', np.count_nonzero(bc_classes == 0))\n",
    "bc_classes = bc_classes.astype(np.int8)\n",
    "# Process io_features into 0 and 1 class\n",
    "io_classes[io_classes == 'b'] = 1\n",
    "io_classes[io_classes == 'g'] = -1\n",
    "print('Number of bad: ', np.count_nonzero(io_classes == 1))\n",
    "print('Number of good: ', np.count_nonzero(io_classes == 0))\n",
    "io_classes = io_classes.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-center data\n",
    "bc_features -= np.mean(bc_features, axis=0)\n",
    "io_features -= np.mean(io_features, axis=0)\n",
    "# 1-center std\n",
    "bc_features /= np.std(bc_features, axis=0)\n",
    "io_features = np.divide(io_features, np.std(io_features, axis=0), where=np.std(io_features, axis=0) != 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568,) int8\n",
      "(568, 30)\n",
      "(350,) int8\n",
      "(350, 34)\n"
     ]
    }
   ],
   "source": [
    "print(bc_classes.shape, bc_classes.dtype)\n",
    "print(bc_features.shape)\n",
    "print(io_classes.shape, io_classes.dtype)\n",
    "print(io_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Loads cross validation framework\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "import seaborn as sn\n",
    "bc_xtrain, bc_xtest, bc_ytrain, bc_ytest = train_test_split(bc_features, bc_classes, test_size=.2)\n",
    "io_xtrain, io_xtest, io_ytrain, io_ytest = train_test_split(io_features, io_classes, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def logistic_loss(features, label, x, l):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\"\"\"\n",
    "    return np.log(1.+np.exp(-label*np.dot(features, x)))+l*np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_grad(features, label, x, l):\n",
    "    \"\"\" Computes the logistic gradient for a Labeled point\"\"\"\n",
    "    return (-label*features*np.exp(-label*np.dot(features, x)))/(1.+np.exp(-label*np.dot(features, x)))+2.*l*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_loss(features, label, x, l):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\"\"\"\n",
    "    return max(0., 1.-label*np.dot(features, x))+l*np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_grad(features, label, x, l):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\"\"\"\n",
    "    if 1.-label*np.dot(features, x) < 0.:\n",
    "        return 0.\n",
    "    else:\n",
    "        return -label*features+2.*l*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_square_loss(features, label, x, l):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\"\"\"\n",
    "    return max(0., 1.-label*np.dot(features, x))**2+l*np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_square_grad(features, label, x, l):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\"\"\"\n",
    "    if 1.-label*np.dot(features, x) < 0.:\n",
    "        return 0.\n",
    "    else:\n",
    "        return -2.*label*features*(1.-label*np.dot(features, x))+2.*l*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def template(x_init, features, labels, loss_function, gradient_loss_function, n_epochs, lamb, learning_rate=1e-3):\n",
    "    x = x_init\n",
    "    n_samples = len(features)\n",
    "    n_print = n_epochs // 10\n",
    "    for epoch in range(n_epochs):\n",
    "        ############ A REMPLIR\n",
    "        grad = XXXXX\n",
    "        \n",
    "        x -= learning_rate * grad\n",
    "        \n",
    "        # Compute loss of whole dataset\n",
    "        if epoch % n_print == 0:\n",
    "            loss = np.mean([loss_function(f, l, x, lamb) for f, l in zip(features, labels)])\n",
    "            print('Epoch ', epoch+1, ' Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preds(x, tefeatures):\n",
    "    p = 1. / (1. + np.exp(-np.dot(tefeatures, x)))\n",
    "    p[p < .5] = -1\n",
    "    p[p >= .5] = 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(real, preds):\n",
    "    return np.sum(real == preds) / float(real.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def ggwp(algo_descent, n_epochs, reg, momentum=None, learning_rate=1e-3):\n",
    "    for loss_type in ((logistic_loss, logistic_grad), (hinge_loss, hinge_grad), (hinge_square_loss, hinge_square_grad)):\n",
    "        for i, dataset in enumerate(((bc_xtrain, bc_ytrain, bc_xtest, bc_ytest), (io_xtrain, io_ytrain, io_xtest, io_ytest))):\n",
    "            loss = loss_type[0]\n",
    "            grad = loss_type[1]\n",
    "            trfeatures, trlabels = dataset[0], dataset[1]\n",
    "            tefeatures, telabels = dataset[2], dataset[3]\n",
    "            x_init = np.zeros(trfeatures[0].shape[0])\n",
    "            print('XXXXXXXXXXXXXXXXXXXXXXX\\nDataset', i, 'Loss type', loss.__name__)\n",
    "            start = time.time()\n",
    "            x = algo_descent(x_init, trfeatures, trlabels, loss, grad, n_epochs, reg, momentum)\n",
    "            print('Time elapsed', time.time() - start)\n",
    "            print('Accuracy', accuracy(telabels, preds(x, tefeatures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch gradient descent\n",
    "def batch_gd(x_init, features, labels, loss_function, gradient_loss_function, n_epochs, lamb, momentum=None, learning_rate=1e-3):\n",
    "    x = x_init\n",
    "    n_samples = len(features)\n",
    "    n_print = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        ############ A REMPLIR\n",
    "        grad = np.mean([gradient_loss_function(f, lab, x, lamb) for f, lab in zip(features, labels)], axis=0)\n",
    "        if momentum:\n",
    "            x = x*momentum - learning_rate*grad\n",
    "        else:\n",
    "            x -= learning_rate * grad\n",
    "        # Compute loss of whole dataset\n",
    "        if epoch+1 % n_print == 0:\n",
    "            loss = np.mean([loss_function(f, l, x, lamb) for f, l in zip(features, labels)])\n",
    "            print('Epoch ', epoch+1, ' Loss: ', loss)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch gradient descent\n",
    "def sgd(x_init, features, labels, loss_function, gradient_loss_function, n_epochs, lamb, momentum=None,learning_rate=1e-3):\n",
    "    x = x_init\n",
    "    n_samples = len(features)\n",
    "    n_print = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        for _ in range(n_samples):\n",
    "            i = np.random.randint(n_samples)\n",
    "            grad = gradient_loss_function(features[i], labels[i], x, lamb)\n",
    "            if momentum:\n",
    "                x = x*momentum - learning_rate*grad\n",
    "            else:\n",
    "                x -= learning_rate * grad\n",
    "        # Compute loss of whole dataset\n",
    "        if epoch+1 % n_print == 0:\n",
    "            loss = np.mean([loss_function(f, l, x, lamb) for f, l in zip(features, labels)])\n",
    "            print('Epoch ', epoch+1, ' Loss: ', loss)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type logistic_loss\n",
      "Time elapsed 1.8253300189971924\n",
      "Accuracy 0.929824561404\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type logistic_loss\n",
      "Time elapsed 1.096635103225708\n",
      "Accuracy 0.714285714286\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type hinge_loss\n",
      "Time elapsed 0.9767379760742188\n",
      "Accuracy 0.921052631579\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type hinge_loss\n",
      "Time elapsed 0.6361169815063477\n",
      "Accuracy 0.7\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type hinge_square_loss\n",
      "Time elapsed 1.651313066482544\n",
      "Accuracy 0.956140350877\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type hinge_square_loss\n",
      "Time elapsed 1.0646250247955322\n",
      "Accuracy 0.842857142857\n"
     ]
    }
   ],
   "source": [
    "ggwp(batch_gd, 100, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type logistic_loss\n",
      "Time elapsed 2.532710075378418\n",
      "Accuracy 0.912280701754\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type logistic_loss\n",
      "Time elapsed 1.6538920402526855\n",
      "Accuracy 0.685714285714\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type hinge_loss\n",
      "Time elapsed 1.4495658874511719\n",
      "Accuracy 0.912280701754\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type hinge_loss\n",
      "Time elapsed 1.0006318092346191\n",
      "Accuracy 0.842857142857\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 0 Loss type hinge_square_loss\n",
      "Time elapsed 2.366858959197998\n",
      "Accuracy 0.964912280702\n",
      "XXXXXXXXXXXXXXXXXXXXXXX\n",
      "Dataset 1 Loss type hinge_square_loss\n",
      "Time elapsed 1.474794864654541\n",
      "Accuracy 0.7\n"
     ]
    }
   ],
   "source": [
    "ggwp(sgd, 100, 1e-3, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
